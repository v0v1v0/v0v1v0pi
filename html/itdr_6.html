<div class="container">

<table style="width: 100%;"><tr>
<td>itdr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Integral Transformation Methods of Estimating SDR Subspaces in Regression.</h2>

<h3>Description</h3>

<p>The “<em>itdr()</em>” function computes a basis for sufficient dimension reduction subspaces
in regression.
</p>


<h3>Usage</h3>

<pre><code class="language-R">itdr(y,x,d,m=50,wx=0.1,wy=1,wh=1.5,space="mean",
xdensity="normal",method="FM",x.scale=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>The n-dimensional response vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>The design matrix of the predictors with dimension n-by-p.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>
<p>An integer specifying the dimension of the sufficient dimension reduction subspace.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>An integer specifying the number of omega values to use in invFM method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wx</code></td>
<td>
<p>(default 0.1). Tuning parameter for predictor variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wy</code></td>
<td>
<p>(default 1). Tuning parameter for response variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wh</code></td>
<td>
<p>(default 1.5). Bandwidth of the kernel density estimation function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>space</code></td>
<td>
<p>(default “mean”). Specifies whether to estimate the central mean subspace (“mean”) or the central subspace (“pdf”).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xdensity</code></td>
<td>
<p>(default “normal”). Density function of predictor variables. Options are
“normal”  for multivariate normal distribution,
“elliptic”  for elliptical contoured distribution, or
“kernel” for unkown distribution estimated using kernel smoothing method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>(default “FM”). Integral transformation method. “FM” for the Fourier transformation method (Zhu and Zeng 2006),
“CM” for convolution transformation method (Zeng and Zhu 2010),
“iht” for the iterative Hessian transformation method (Cook and Li 2002),
and “invFM” for the Fourier transformation approach for inverse dimension reduction method (Weng and Yin, 2018).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x.scale</code></td>
<td>
<p>(default TURE). If TRUE, scale the predictor variables.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Let m(<b>x</b>)=E[y|<b>X</b>=<b>x</b>]. The “<em>itdr()</em>” function computes the integral transformation of the gradient of the mean function m(<b>x</b>), which is defined as
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol\psi(\boldsymbol\omega) =\int \frac{\partial}{\partial \textbf{x}}m(\textbf{x}) W(\textbf{x},\boldsymbol\omega)f(\textbf{x})d\textbf{x},</code>
</p>

<p>where <code class="reqn">W(\textbf{x},\boldsymbol\omega)</code> is a non degenerate kernel function and an absolutely integrable function. For Fourier transformation (FM) method and for convolution transformation (CM) method <code class="reqn">W(\textbf{x},\boldsymbol\omega)=\exp(i\boldsymbol\omega^T\textbf{x})</code> 
and <code class="reqn">W(\textbf{x},\boldsymbol\omega)=H(\textbf{x}-\boldsymbol\omega)=(2\pi\sigma_w^2)^{-p/2}\exp(-(\textbf{x}-\boldsymbol{\omega})^T(\textbf{x}-\boldsymbol\omega)/(2\sigma_w^2))</code> 
where is <code class="reqn">\sigma_w^2</code> is the turning parameter for predictor variables.
The candidate matrix to estimate the central mean subspace (CMS) is
</p>
<p style="text-align: center;"><code class="reqn">\textbf{M}_{CMS}=\int \boldsymbol\psi(\boldsymbol\omega) \boldsymbol\psi(\boldsymbol\omega)^T K(\boldsymbol\omega)d\boldsymbol\omega, </code>
</p>

<p>where <code class="reqn">K(\boldsymbol{\omega})=(2\pi \sigma_w^2)^{-p/2}\exp{(-||\boldsymbol{\omega}||}/2\sigma_w^2)</code> under “FM”, and <code class="reqn">K(\boldsymbol{\omega})=1</code> under “CM”.
Here, <code class="reqn">\sigma_w^2</code> is a tuning parameter and it refers as "tuning parameter for the predictor variables" and denoted by “wx” in all functions.
</p>
<p>Let <code class="reqn">\{T_v(y)=H(y,v),~ for~~ y,v\in \mathcal{R}\}</code> be the family of transformations for the response variable. That is, <code class="reqn">v \in \mathcal{R}</code>, the mean
response of <code class="reqn">T_v(y)</code> is <code class="reqn">m(\boldsymbol{\omega},v)=E[H(y,v)\vert \textbf{X}=\textbf{x}]</code>. Then, integral transformation for the gradient of
<code class="reqn">m(\boldsymbol{\omega},v)</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol{\psi}(\boldsymbol{\omega},v)=\int \frac{\partial}{\partial \textbf{x}}m(\textbf{x},v) W(\textbf{x},\boldsymbol{\omega})f(\textbf{x})d\textbf{x},</code>
</p>

<p>where <code class="reqn">W(\textbf{x},\boldsymbol{\omega})</code> is define as above. Then, for estimating the central subspace (CS) the
candidate matrix is defined as
</p>
<p style="text-align: center;"><code class="reqn">\textbf{M}_{CS}=\int H(y_1,v)H(y_2,v)dv \int \boldsymbol{\psi}(\boldsymbol{\omega}) \bar{\boldsymbol{\psi}}(\boldsymbol{\omega})^T K(\boldsymbol{\omega})d\boldsymbol{\omega},</code>
</p>

<p>where <code class="reqn">K(\boldsymbol{\omega})</code> is the same as above, and <code class="reqn">H(y,v)=(2\pi \sigma_t^2)^{-1/2}\exp(v^2/(2\sigma_t^2))</code> under  “FM”,
and <code class="reqn">H(y,v)=(2\pi \sigma_t^2)^{-1/2}\exp((y-v)^2/(2\sigma_t^2))</code> under “CM”.
Here <code class="reqn">\sigma_t^2</code> is a tuning parameter and it refers as the "tuning parameter for the response variable" and is denote by “wy” in all functions.
</p>
<p><b>Remark:</b> There is only one tuning parameter in the candidate matrix for estimating of the CMS, and there are two tuning
parameters in the candidate matrix for estimating of the CS.
</p>
<p><b>“invFM” method:</b>
</p>
<p>Let <code class="reqn">(\textbf{y}_i,\textbf{x}_i), i =1,\cdots,n</code>, be a random sample, and assume that the dimension of <code class="reqn">S_{E(\textbf{Z} | \textbf{Y})}</code> is known to be <em>d</em>.
Then, for a random finite sequence of <code class="reqn">\boldsymbol{\omega}_j \in {R}^p</code>, <code class="reqn">j=1,\cdots,t</code>, compute <code class="reqn">\widehat{\boldsymbol{\psi}}(\boldsymbol{\omega}_j)</code> as follows (Weng and Yin, 2018):
</p>
<p style="text-align: center;"><code class="reqn">\widehat{\boldsymbol{\psi}}(\boldsymbol{\omega}_j)=n^{-1}\sum_{k=1}^n \exp( i \boldsymbol{\omega}_j^T\textbf{y}_k)\widehat{\textbf{Z}}_k, j=1,\cdots,t,</code>
</p>

<p>where <code class="reqn">\widehat{\textbf{Z}}_j=\boldsymbol{\Sigma}_{x}^{-1/2}(\textbf{x}_i-\overline{\textbf{x}})</code>. Now, let
<code class="reqn">\textbf{a}(\boldsymbol{\omega}_j)=Real(\widehat{\boldsymbol{\psi}}(\boldsymbol{\omega}_j))</code>, and <code class="reqn">\textbf{b}(\boldsymbol{\omega}_j)=Image(\widehat{\boldsymbol{\psi}}(\boldsymbol{\omega}_j))</code>. Then,
<code class="reqn">\widehat{\boldsymbol{\Psi}}= (\textbf{a}(\boldsymbol{\omega}_1),\textbf{b}(\boldsymbol{\omega}_1),\cdots,\textbf{a}(\boldsymbol{\omega}_t),\textbf{b}(\boldsymbol{\omega}_t))</code>, for some <code class="reqn">t &gt; 0</code>, and the population kernel matrix is
<code class="reqn">\widehat{\textbf{V}} = \widehat{\boldsymbol{\Psi}}\widehat{\boldsymbol{\Psi}}^T</code>. Finally, use the <em>d</em>-leading eigenvectors of <code class="reqn">\widehat{\textbf{V}}</code> as an estimate for the central subspace.
</p>
<p><b>Remark: </b>We use <em>w</em> instead of <code class="reqn">\boldsymbol{\omega}_1,\cdots,\boldsymbol{\omega}_t</code> in the <em>itdr()</em> function.
</p>


<h3>Value</h3>

<p>The outputs are a p-by-d matrix and a p-by-p matrix defined as follows.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>eta_hat</code></td>
<td>
<p>The estimated p by d matrix, whose coloumns form a basis of the CMS/CS.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>
<p>The estimated p by p candidate matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eigenvalues</code></td>
<td>
<p>Eigenvalues of <code class="reqn">\widehat{\bold{V}}</code> from the “invFM” method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>psi</code></td>
<td>
<p>Estimation for <code class="reqn">\widehat{\bold{\Psi}}</code> from the “invFM” method.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Cook R. D. and Li, B., (2002).
Dimension Reduction for Conditional Mean in Regression. <em>The Annals of Statistics</em>. 30, 455-474.
</p>
<p>Weng J. and Yin X. (2018).
Fourier Transform Approach for Inverse Dimension Reduction Method. <em>Journal of Nonparametric Statistics</em>. 30, 4, 1029-0311.
</p>
<p>Zeng P. and Zhu Y. (2010).
An Integral Transform Method for Estimating the Central Mean and Central Subspaces. <em>Journal of Multivariate Analysis</em>. 101, 1, 271–290.
</p>
<p>Zhu Y. and Zeng P. (2006).
Fourier Methods for Estimating the Central Subspace and Central Mean Subspace in Regression. <em>Journal of the American Statistical Association</em>. 101, 476, 1638–1651.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(automobile)
head(automobile)
automobile.na &lt;- na.omit(automobile)
wx &lt;- .14
wy &lt;- .9
wh &lt;- 1.5
d &lt;- 2
p &lt;- 13
df &lt;- cbind(automobile[, c(26, 10, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 24, 25)])
dff &lt;- as.matrix(df)
automobi &lt;- dff[complete.cases(dff), ]
y &lt;- automobi[, 1]
x &lt;- automobi[, c(2:14)]
xt &lt;- scale(x)
fit.F_CMS &lt;- itdr(y, xt, d, wx, wy, wh, space = "pdf", xdensity = "normal", method = "FM")
round(fit.F_CMS$eta_hat, 2)

</code></pre>


</div>