<div class="container">

<table style="width: 100%;"><tr>
<td>vectorize</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Vectorize data</h2>

<h3>Description</h3>

<p>This function turns texts into feature vectors.
</p>


<h3>Usage</h3>

<pre><code class="language-R">vectorize(
  input,
  tokens,
  remove_punct,
  remove_symbols,
  remove_numbers,
  lowercase,
  n,
  weighting,
  trim,
  threshold
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>input</code></td>
<td>
<p>This should be a <code>quanteda</code> corpus object with the author names as a docvar called "author". Typically, this is the output of the <code>create_corpus()</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tokens</code></td>
<td>
<p>The type of tokens to extract, either "character" or "word".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remove_punct</code></td>
<td>
<p>A logical value. FALSE to keep the punctuation marks or TRUE to remove them.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remove_symbols</code></td>
<td>
<p>A logical value. TRUE removes symbols and FALSE keeps them.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remove_numbers</code></td>
<td>
<p>A logical value. TRUE removes numbers and FALSE keeps them.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lowercase</code></td>
<td>
<p>A logical value. TRUE transforms all tokens to lower case.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>The order or size of the n-grams being extracted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weighting</code></td>
<td>
<p>The type of weighting to use, "rel" for relative frequencies, "tf-idf", or "boolean".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trim</code></td>
<td>
<p>A logical value. If TRUE then only the most frequent tokens are kept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>
<p>A numeric value indicating how many most frequent tokens to keep.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>All the authorship analysis functions call <code>vectorize()</code> with the standard parameters for the algorithm selected. This function is therefore left only for those users who want to modify these parameters or for convenience if the same dfm has to be reused by the algorithms so to avoid vectorizing the same data many times. Most users who only need to run a standard analysis do not need use this function.
</p>


<h3>Value</h3>

<p>A dfm (document-feature matrix) containing each text as a feature vector. N-gram tokenisation does not cross sentence boundaries.
</p>


<h3>Examples</h3>

<pre><code class="language-R">mycorpus &lt;- quanteda::corpus("The cat sat on the mat.")
quanteda::docvars(mycorpus, "author") &lt;- "author1"
matrix &lt;- vectorize(mycorpus, tokens = "character", remove_punct = FALSE, remove_symbols = TRUE,
remove_numbers = TRUE, lowercase = TRUE, n = 5, weighting = "rel", trim = TRUE, threshold = 1500)

</code></pre>


</div>