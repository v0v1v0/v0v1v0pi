<div class="container">

<table style="width: 100%;"><tr>
<td>est_score</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Estimate examinees' ability (proficiency) parameters</h2>

<h3>Description</h3>

<p>This function estimates examinees' latent ability parameters. Available scoring methods are maximum likelihood estimation (ML),
maximum likelihood estimation with fences (MLF; Han, 2016), weighted likelihood estimation (Warm, 1989), maximum a posteriori estimation
(MAP; Hambleton et al., 1991), expected a posteriori estimation (EAP; Bock &amp; Mislevy, 1982), EAP summed scoring
(Thissen et al., 1995; Thissen &amp; Orlando, 2001), and inverse test characteristic curve (TCC) scoring
(e.g., Kolen &amp; Brennan, 2004; Kolen &amp; Tong, 2010; Stocking, 1996).
</p>


<h3>Usage</h3>

<pre><code class="language-R">est_score(x, ...)

## Default S3 method:
est_score(
  x,
  data,
  D = 1,
  method = "ML",
  range = c(-5, 5),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  fence.a = 3,
  fence.b = NULL,
  tol = 1e-04,
  max.iter = 100,
  se = TRUE,
  stval.opt = 1,
  intpol = TRUE,
  range.tcc = c(-7, 7),
  missing = NA,
  ncore = 1,
  ...
)

## S3 method for class 'est_irt'
est_score(
  x,
  method = "ML",
  range = c(-5, 5),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  fence.a = 3,
  fence.b = NULL,
  tol = 1e-04,
  max.iter = 100,
  se = TRUE,
  stval.opt = 1,
  intpol = TRUE,
  range.tcc = c(-7, 7),
  missing = NA,
  ncore = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...) or an object of
class <code>est_irt</code> obtained from the function <code>est_irt</code>. See <code>irtfit</code>, <code>info</code>,
or <code>simdat</code> for more details about the item metadata. This data frame can be easily obtained using the function <code>shape_df</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to pass to <code>parallel::makeCluster</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A matrix or vector containing examinees' response data for the items in the argument <code>x</code>. When a matrix is used, a row and column indicate
the examinees and items, respectively. When a vector is used, it should contains the item response data for an examinee.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>A character string indicating a scoring method. Available methods are "ML" for the maximum likelihood estimation,
"MLF" for the maximum likelihood estimation with fences, "WL" for the weighted likelihood estimation, "MAP" for the maximum a posteriori estimation,
"EAP" for the expected a posteriori estimation, "EAP.SUM" for the expected a posteriori summed scoring, and "INV.TCC" for the inverse TCC scoring.
Default method is "ML".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>range</code></td>
<td>
<p>A numeric vector of two components to restrict the range of ability scale for the ML, MLF, WL, and MAP scoring methods. Default is c(-5, 5).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>norm.prior</code></td>
<td>
<p>A numeric vector of two components specifying a mean and standard deviation of the normal prior distribution.
These two parameters are used to obtain the gaussian quadrature points and the corresponding weights from the normal distribution. Default is
c(0,1). Ignored if <code>method</code> is "ML", "MLF", "WL", or "INV.TCC".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nquad</code></td>
<td>
<p>An integer value specifying the number of gaussian quadrature points from the normal prior distribution. Default is 41.
Ignored if <code>method</code> is "ML", "MLF", "WL", "MAP", or "INV.TCC".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>A two-column matrix or data frame containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the latent variable prior distribution. The weights and quadrature points can be easily obtained
using the function <code>gen.weight</code>. If NULL and <code>method</code> is "EAP" or "EAP.SUM", default values are used (see the arguments
of <code>norm.prior</code> and <code>nquad</code>). Ignored if <code>method</code> is "ML", "MLF", "WL", "MAP", or "INV.TCC".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fence.a</code></td>
<td>
<p>A numeric value specifying the item slope parameter (i.e., <em>a</em>-parameter) for the two imaginary items in MLF. See below for details.
Default is 3.0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fence.b</code></td>
<td>
<p>A numeric vector of two components specifying the lower and upper fences of item difficulty parameters (i.e., <em>b</em>-parameters)
for the two imaginary items, respectively, in MLF. When <code>fence.b = NULL</code>, the <code>range</code> values were used to set the lower and upper fences of
item difficulty parameters. Default is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>A numeric value of the convergent tolerance for the ML, MLF, WL, MAP, and inverse TCC scoring methods. For the ML, MLF, WL, and MAP,
Newton Raphson method is implemented for optimization. For the inverse TCC scoring, the bisection method is used. Default is 1e-4.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>An positive integer value specifying the maximum number of iterations of Newton Raphson method. Default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>se</code></td>
<td>
<p>A logical value. If TRUE, the standard errors of ability estimates are computed. However, if <code>method</code> is "EAP.SUM" or "INV.TCC", the standard
errors are always returned. Default is TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stval.opt</code></td>
<td>
<p>An positive integer value specifying the starting value option for the ML, MLF, WL, and MAP scoring methods.
Available options are 1 for the brute-force method, 2 for the observed sum score-based method, and 3 for setting to 0. Default is 1.
See below for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intpol</code></td>
<td>
<p>A logical value. If TRUE and <code>method = "INV.TCC"</code>, linear interpolation method is used to approximate the ability estimates
corresponding to the observed sum scores in which ability estimates cannot be obtained using the TCC (e.g., observed sum scores less than
the sum of item guessing parameters). Default is TRUE. See below for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>range.tcc</code></td>
<td>
<p>A numeric vector of two components to be used as the lower and upper bounds of ability estimates when <code>method = "INV.TCC"</code>.
Default is c(-7, 7).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>missing</code></td>
<td>
<p>A value indicating missing values in the response data set. Default is NA. See below for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncore</code></td>
<td>
<p>The number of logical CPU cores to use. Default is 1. See below for details.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For MAP scoring method, only the normal prior distribution is available for the population distribution.
</p>
<p>When there are missing data in the response data set, the missing value must be specified in <code>missing</code>. The missing data are taken into account
when either of ML, MLF, WL, MAP, and EAP is used. When "EAP.SUM" or "INV.TCC" is used, however, any missing responses are replaced with incorrect
responses (i.e., 0s).
</p>
<p>In the maximum likelihood estimation with fences (MLF; Han, 2016), two 2PLM imaginary items are necessary. The first imaginary item serves as the lower
fence and its difficulty parameter (i.e., <em>b</em>-parameters) should be lower than any difficulty parameter values in the test form. Likewise, the second
imaginary item serves as the upper fence and its difficulty parameter should be greater than any difficulty parameter values in the test form. Also, the two
imaginary items should have a very high item slope parameter (i.e., <em>a</em>-parameter) value. See Han (2016) for more details. When <code>fence.b = NULL</code> in MLF,
the function automatically sets the lower and upper fences of item difficulty parameters using the values
in the <code>range</code> argument.
</p>
<p>When "INV.TCC" method is used employing the IRT 3-parameter logistic model (3PLM) in a test, ability estimates for the observed sum scores less than the
sum of item guessing parameters are not attainable. In this case, linear interpolation can be applied by setting <code>intpol = TRUE</code>.
Let <code class="reqn">\theta_{min}</code> and <code class="reqn">\theta_{max}</code> be the minimum and maximum ability estimates and <code class="reqn">\theta_{X}</code> be the ability estimate for
the smallest observed sum score, X, but greater than or equal to the sum of item guessing parameters. When linear interpolation method is used,
the first value of the <code>range.tcc</code> is set to <code class="reqn">\theta_{min}</code>. Then, a linear line is constructed between two points of
(x=<code class="reqn">\theta_{min}</code>, y=0) and (x=<code class="reqn">\theta_{X}</code>, y=X). Also, the first value of the <code>range.tcc</code> is set to <code class="reqn">\theta_{max}</code>, which is
the ability estimates corresponding to the maximum observed sum score. When it comes to the scoring method of "INV.TCC", the standard errors of ability
estimates are computed using an approach suggested by Lim, Davey, and Wells (2020). The code for the inverse TCC scoring was written by modifying
the function <code>irt.eq.tse</code> of the <span class="pkg">SNSequate</span> R package (González, 2014).
</p>
<p>In terms of the starting value to be used for ML, MLF, WL, and MAP scoring methods, the brute-force method is used when <code>stval.opt = 1</code>. With this option,
the log-likelihood values were evaluated at the discrete theta values with increments of 0.1 given <code>range</code>. The theta node that has the largest
log-likelihood is used as the starting value. when <code>stval.opt = 2</code>, the starting value is obtained based on the observed sum score. For example,
if the maximum observed sum score (max.score) is 30 for a test and an examinee has an observed sum score of 20 (obs.score), then the starting value
is "log(obs.score / (max.score - obs.score))". For all incorrect response, the starting value is "log(1 / max.score)" and for all correct responses,
it is "log(max.score / 1)".
</p>
<p>To speed up the ability estimation for ML, MLF, WL, MAP, and EAP methods, this function applies a parallel process using multiple logical CPU cores.
You can set the number of logical CPU cores by specifying a positive integer value in the argument <code>ncore</code>. Default value is 1.
</p>
<p>Note that the standard errors of ability estimates are computed using the Fisher expected information for ML, MLF, WL, and MAP methods.
</p>
<p>To implement WL method, the <code>Pi</code>, <code>Ji</code>, and <code>Ii</code> functions of <span class="pkg">catR</span>
(Magis &amp; Barrada, 2017) were referred.
</p>


<h3>Value</h3>

<p>When <code>method</code> is either of "ML", "MLF", "WL", "MAP", or "EAP", a two column data frame including the ability estimates (1st column)
and the standard errors of ability estimates (2nd column) is returned. When <code>method</code> is "EAP.SUM" or "INV.TCC", a list of two internal
objects are returned. The first object is a three column data frame including the observed sum scores (1st column), the ability estimates (2nd column),
and the standard errors of ability estimates (3rd column). The second object is a score table including the possible raw sum scores
and corresponding ability and standard error estimates.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>est_score(default)</code>: Default method to estimate examinees' latent ability parameters using a data frame <code>x</code> containing the item metadata.
</p>
</li>
<li> <p><code>est_score(est_irt)</code>: An object created by the function <code>est_irt</code>.
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Bock, R. D., &amp; Mislevy, R. J. (1982). Adaptive EAP estimation of ability in a microcomputer environment. <em>Psychometrika, 35</em>, 179-198.
</p>
<p>González, J. (2014). SNSequate: Standard and nonstandard statistical models and methods for test equating.
<em>Journal of Statistical Software, 59</em>, 1-30.
</p>
<p>Hambleton, R. K., Swaminathan, H., &amp; Rogers, H. J. (1991).<em>Fundamentals of item response theory</em>. Newbury Park, CA: Sage.
</p>
<p>Han, K. T. (2016). Maximum likelihood score estimation method with fences for short-length tests and computerized adaptive tests.
<em>Applied psychological measurement, 40</em>(4), 289-301.
</p>
<p>Howard, J. P. (2017). <em>Computational methods for numerical analysis with R</em>. New York:
Chapman and Hall/CRC.
</p>
<p>Kolen, M. J. &amp; Brennan, R. L. (2004). <em>Test Equating, Scaling, and Linking</em> (2nd ed.). New York:
Springer
</p>
<p>Kolen, M. J. &amp; Tong, Y. (2010). Psychometric properties of IRT proficiency estimates.
<em>Educational Measurement: Issues and Practice, 29</em>(3), 8-14.
</p>
<p>Lim, H., Davey, T., &amp; Wells, C. S. (2020). A recursion-based analytical approach to evaluate the performance of MST.
<em>Journal of Educational Measurement, 58</em>(2), 154-178.
</p>
<p>Magis, D., &amp; Barrada, J. R. (2017). Computerized adaptive testing with R: Recent updates of the package catR.
<em>Journal of Statistical Software, 76</em>, 1-19.
</p>
<p>Stocking, M. L. (1996). An alternative method for scoring adaptive tests.
<em>Journal of Educational and Behavioral Statistics, 21</em>(4), 365-389.
</p>
<p>Thissen, D. &amp; Orlando, M. (2001). Item response theory for items scored in two categories. In D. Thissen &amp; H. Wainer (Eds.),
<em>Test scoring</em> (pp.73-140). Mahwah, NJ: Lawrence Erlbaum.
</p>
<p>Thissen, D., Pommerich, M., Billeaud, K., &amp; Williams, V. S. (1995). Item Response Theory
for Scores on Tests Including Polytomous Items with Ordered Responses. <em>Applied Psychological
Measurement, 19</em>(1), 39-49.
</p>
<p>Warm, T. A. (1989). Weighted likelihood estimation of ability in item response theory. <em>Psychometrika, 54</em>(3),
427-450.
</p>


<h3>See Also</h3>

<p><code>irtfit</code>, <code>info</code>, <code>simdat</code>, <code>shape_df</code>, <code>gen.weight</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## the use of a "-prm.txt" file obtained from a flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameters and transform them to item metadata
x &lt;- bring.flexmirt(file = flex_prm, "par")$Group1$full_df

# generate examinees abilities
set.seed(12)
theta &lt;- rnorm(10)

# simulate the item response data
data &lt;- simdat(x, theta, D = 1)


# estimate the abilities using ML
est_score(x, data, D = 1, method = "ML", range = c(-4, 4), se = TRUE)

# estimate the abilities using WL
est_score(x, data, D = 1, method = "WL", range = c(-4, 4), se = TRUE)

# estimate the abilities using MLF with default fences of item difficulty parameters
est_score(x, data, D = 1, method = "MLF", fence.a = 3.0, fence.b = NULL, se = TRUE)

# estimate the abilities using MLF with different fences of item difficulty parameters
est_score(x, data, D = 1, method = "MLF", fence.a = 3.0, fence.b = c(-7, 7), se = TRUE)

# estimate the abilities using MAP
est_score(x, data, D = 1, method = "MAP", norm.prior = c(0, 1), nquad = 30, se = TRUE)

# estimate the abilities using EAP
est_score(x, data, D = 1, method = "EAP", norm.prior = c(0, 1), nquad = 30, se = TRUE)

# estimate the abilities using EAP summed scoring
est_score(x, data, D = 1, method = "EAP.SUM", norm.prior = c(0, 1), nquad = 30)

# estimate the abilities using inverse TCC scoring
est_score(x, data, D = 1, method = "INV.TCC", intpol = TRUE, range.tcc = c(-7, 7))


</code></pre>


</div>