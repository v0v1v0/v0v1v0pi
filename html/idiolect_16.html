<div class="container">

<table style="width: 100%;"><tr>
<td>tokenize_sents</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tokenize to sentences</h2>

<h3>Description</h3>

<p>This function turns a corpus of texts into a <code>quanteda</code> tokens object of sentences.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tokenize_sents(corpus, model = "en_core_web_sm")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>corpus</code></td>
<td>
<p>A <code>quanteda</code> corpus object, typically the output of the <code>create_corpus()</code> function or the output of <code>contentmask()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>The spacy model to use. The default is "en_core_web_sm".</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function first split each text into paragraphs by splitting at new line markers and then uses spacy to tokenize each paragraph into sentences. The function accepts a plain text corpus input or the output of <code>contentmask()</code>. This function is necessary to prepare the data for <code>lambdaG()</code>.
</p>


<h3>Value</h3>

<p>A <code>quanteda</code> tokens object where each token is a sentence.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
toy.pos &lt;- corpus("the N was on the N . he did n't move \n N ; \n N N")
tokenize_sents(toy.pos)

## End(Not run)

</code></pre>


</div>