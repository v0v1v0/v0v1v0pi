<div class="container">

<table style="width: 100%;"><tr>
<td>FeatureImp</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feature importance</h2>

<h3>Description</h3>

<p><code>FeatureImp</code> computes feature importance for prediction models. The
importance is measured as the factor by which the model's prediction error
increases when the feature is shuffled.
</p>


<h3>Details</h3>

<p>To compute the feature importance for a single feature, the model prediction
loss (error) is measured before and after shuffling the values of the
feature. By shuffling the feature values, the association between the outcome
and the feature is destroyed. The larger the increase in prediction error,
the more important the feature was. The shuffling is repeated to get more
accurate results, since the permutation feature importance tends to be quite
unstable.
Read the Interpretable Machine Learning book to learn about feature
importance in detail:
<a href="https://christophm.github.io/interpretable-ml-book/feature-importance.html">https://christophm.github.io/interpretable-ml-book/feature-importance.html</a>
</p>
<p>The loss function can be either specified via a string, or by handing a
function to <code>FeatureImp()</code>. If you want to use your own loss function it
should have this signature:
</p>
<div class="sourceCode"><pre>function(actual, predicted)
</pre></div>
<p>Using the string is
a shortcut to using loss functions from the <code>Metrics</code> package. Only use
functions that return a single performance value, not a vector. Allowed
losses are: <code>"ce"</code>, <code>"f1"</code>, <code>"logLoss"</code>, <code>"mae"</code>, <code>"mse"</code>, <code>"rmse"</code>, <code>"mape"</code>,
<code>"mdae"</code>, <code>"msle"</code>, <code>"percent_bias"</code>, <code>"rae"</code>, <code>"rmse"</code>, <code>"rmsle"</code>, <code>"rse"</code>,
<code>"rrse"</code> and <code>"smape"</code>.
</p>
<p>See <code>library(help = "Metrics")</code> to get a list of functions.
</p>


<h3>Parallelization</h3>

<p>Parallelization is supported via package <a href="https://CRAN.R-project.org/package=future"><span class="pkg">future</span></a>.
To initialize future-based parallelization, select an appropriate backend and
specify the amount of workers.
For example, to use a PSOCK based cluster backend do:
</p>
<div class="sourceCode r"><pre>future::plan(multisession, workers = 2)
&lt;iml function here&gt;
</pre></div>
<p>Consult the resources of the <a href="https://CRAN.R-project.org/package=future"><span class="pkg">future</span></a> package for more parallel
backend options.
</p>


<h3>Super class</h3>

<p><code>iml::InterpretationMethod</code> -&gt; <code>FeatureImp</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>loss</code></dt>
<dd>
<p>(<code>character(1)</code> | function)<br>
The loss function. Either the name of a loss (e.g. <code>"ce"</code> for
classification or <code>"mse"</code>) or a function.</p>
</dd>
<dt><code>original.error</code></dt>
<dd>
<p>(<code>numeric(1)</code>)<br>
The loss of the model before perturbing features.</p>
</dd>
<dt><code>n.repetitions</code></dt>
<dd>
<p>integer<br>
Number of repetitions.</p>
</dd>
<dt><code>compare</code></dt>
<dd>
<p>(<code>character(1)</code>)<br> Either <code>"ratio"</code> or <code>"difference"</code>,
depending on whether the importance was calculated as difference
between original model error and model error after permutation or as
ratio.</p>
</dd>
<dt><code>features</code></dt>
<dd>
<p>(<code>list</code>)<br> Features for which importance scores are to
be calculated. The names are the feature/group names, while the contents
specify which feature(s) are to be permuted.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-FeatureImp-new"><code>FeatureImp$new()</code></a>
</p>
</li>
<li> <p><a href="#method-FeatureImp-clone"><code>FeatureImp$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href="../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot"><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href="../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print"><code>iml::InterpretationMethod$print()</code></a></span></li>
</ul></details><hr>
<a id="method-FeatureImp-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Create a FeatureImp object
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureImp$new(
  predictor,
  loss,
  compare = "ratio",
  n.repetitions = 5,
  features = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt>
<dd>
<p>Predictor<br>
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>loss</code></dt>
<dd>
<p>(<code>character(1)</code> | function)<br>
The loss function. Either the name of a loss (e.g. <code>"ce"</code> for
classification or <code>"mse"</code>) or a function. See Details for allowed
losses.</p>
</dd>
<dt><code>compare</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
Either <code>"ratio"</code> or <code>"difference"</code>.
Should importance be measured as the difference or as the ratio of
original model error and model error after permutation?
</p>

<ul>
<li>
<p> Ratio: error.permutation/error.orig
</p>
</li>
<li>
<p> Difference: error.permutation - error.orig
</p>
</li>
</ul>
</dd>
<dt><code>n.repetitions</code></dt>
<dd>
<p>(<code>numeric(1)</code>)<br>
How often should the shuffling of the feature be repeated?
The higher the number of repetitions the more stable and accurate the
results become.</p>
</dd>
<dt><code>features</code></dt>
<dd>
<p>(<code style="white-space: pre;">⁠character or list⁠</code>)<br>
For which features do you want importance scores calculated. The default
value of <code>NULL</code> implies all features. Use a named list of character vectors
to define groups of features for which joint importance will be calculated.
See examples.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>(data.frame)<br>
data.frame with the results of the feature importance computation. One
row per feature with the following columns:
</p>

<ul>
<li>
<p> importance.05 (5% quantile of importance values from the repetitions)
</p>
</li>
<li>
<p> importance (median importance)
</p>
</li>
<li>
<p> importance.95 (95% quantile) and the permutation.error (median error
over all repetitions).
</p>
</li>
</ul>
<p>The distribution of the importance is also visualized as a bar in the
plots, the median importance over the repetitions as a point.
</p>


<hr>
<a id="method-FeatureImp-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureImp$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>References</h3>

<p>Fisher, A., Rudin, C., and Dominici, F. (2018). Model Class Reliance:
Variable Importance Measures for any Machine Learning Model Class, from the
"Rashomon" Perspective. Retrieved from http://arxiv.org/abs/1801.01489
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("rpart")
# We train a tree on the Boston dataset:
data("Boston", package = "MASS")
tree &lt;- rpart(medv ~ ., data = Boston)
y &lt;- Boston$medv
X &lt;- Boston[-which(names(Boston) == "medv")]
mod &lt;- Predictor$new(tree, data = X, y = y)


# Compute feature importances as the performance drop in mean absolute error
imp &lt;- FeatureImp$new(mod, loss = "mae")

# Plot the results directly
plot(imp)


# Since the result is a ggplot object, you can extend it:
library("ggplot2")
plot(imp) + theme_bw()
# If you want to do your own thing, just extract the data:
imp.dat &lt;- imp$results
head(imp.dat)
ggplot(imp.dat, aes(x = feature, y = importance)) +
  geom_point() +
  theme_bw()

# We can also look at the difference in model error instead of the ratio
imp &lt;- FeatureImp$new(mod, loss = "mae", compare = "difference")

# Plot the results directly
plot(imp)

# We can calculate feature importance for a subset of features 
imp &lt;- FeatureImp$new(mod, loss = "mae", features = c("crim", "zn", "indus"))
plot(imp)

# We can calculate joint importance of groups of features
groups = list(
 grp1 = c("crim", "zn", "indus", "chas"),
 grp2 = c("nox", "rm", "age", "dis"),
 grp3 = c("rad", "tax", "ptratio", "black", "lstat")
)
imp &lt;- FeatureImp$new(mod, loss = "mae", features = groups)
plot(imp)

# FeatureImp also works with multiclass classification.
# In this case, the importance measurement regards all classes
tree &lt;- rpart(Species ~ ., data = iris)
X &lt;- iris[-which(names(iris) == "Species")]
y &lt;- iris$Species
mod &lt;- Predictor$new(tree, data = X, y = y, type = "prob")

# For some models we have to specify additional arguments for the predict function
imp &lt;- FeatureImp$new(mod, loss = "ce")
plot(imp)

# For multiclass classification models, you can choose to only compute
# performance for one class.
# Make sure to adapt y
mod &lt;- Predictor$new(tree,
  data = X, y = y == "virginica",
  type = "prob", class = "virginica"
)
imp &lt;- FeatureImp$new(mod, loss = "ce")
plot(imp)
</code></pre>


</div>