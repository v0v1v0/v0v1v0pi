<div class="container">

<table style="width: 100%;"><tr>
<td>icc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Intraclass correlation coefficient (ICC) for oneway and twoway models</h2>

<h3>Description</h3>

<p>Computes single score or average score ICCs as an index of interrater reliability of quantitative data. Additionally, F-test and confidence interval are computed.
</p>


<h3>Usage</h3>

<pre><code class="language-R">icc(ratings, model = c("oneway", "twoway"), 
    type = c("consistency", "agreement"), 
    unit = c("single", "average"), r0 = 0, conf.level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>ratings</code></td>
<td>
<p>n*m matrix or dataframe, n subjects m raters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>a character string specifying if a '"oneway"' model (default) with row effects random, or a '"twoway"' model with column and row effects random should be applied. You can specify just the initial letter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>a character string specifying if '"consistency"' (default) or '"agreement"' between raters should be estimated. If a '"oneway"' model is used, only '"consistency"' could be computed. You can specify just the initial letter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>unit</code></td>
<td>
<p>a character string specifying the unit of analysis: Must be one of '"single"' (default) or '"average"'. You can specify just the initial letter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r0</code></td>
<td>
<p>specification of the null hypothesis r = r0. Note that a one sided test (H1: r &gt; r0) is performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf.level</code></td>
<td>
<p>confidence level of the interval.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Missing data are omitted in a listwise way.<br>
When considering which form of ICC is appropriate for an actual set of data, one has take several decisions (Shrout &amp; Fleiss, 1979):<br><br>
1. Should only the subjects be considered as random effects ('"oneway"' model) or are subjects and raters randomly chosen from a bigger pool of persons ('"twoway"' model).<br><br>
2. If differences in judges' mean ratings are of interest, interrater '"agreement"' instead of '"consistency"' should be computed.<br><br>
3. If the unit of analysis is a mean of several ratings, unit should be changed to '"average"'. In most cases, however, single values (unit='"single"') are regarded.
</p>


<h3>Value</h3>

<p>A list with class '"icclist"' containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>$subjects</code></td>
<td>
<p>the number of subjects examined.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$raters</code></td>
<td>
<p>the number of raters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$model</code></td>
<td>
<p>a character string describing the selected model for the analysis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$type</code></td>
<td>
<p>a character string describing the selected type of interrater reliability.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$unit</code></td>
<td>
<p>a character string describing the unit of analysis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$icc.name</code></td>
<td>
<p>a character string specifying the name of ICC according to McGraw &amp; Wong (1996).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$value</code></td>
<td>
<p>the intraclass correlation coefficient.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$r0</code></td>
<td>
<p>the specified null hypothesis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$Fvalue</code></td>
<td>
<p>the value of the F-statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$df1</code></td>
<td>
<p>the numerator degrees of freedom.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$df2</code></td>
<td>
<p>the denominator degrees of freedom.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$p.value</code></td>
<td>
<p>the p-value for a two-sided test.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$conf.level</code></td>
<td>
<p>the confidence level for the interval.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$lbound</code></td>
<td>
<p>the lower bound of the confidence interval.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>$ubound</code></td>
<td>
<p>the upper bound of the confidence interval.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Matthias Gamer</p>


<h3>References</h3>

<p>Bartko, J.J. (1966). The intraclass correlation coefficient as a measure of reliability. Psychological Reports, 19, 3-11.<br><br>
McGraw, K.O., &amp; Wong, S.P. (1996), Forming inferences about some intraclass correlation coefficients. Psychological Methods, 1, 30-46.<br><br>
Shrout, P.E., &amp; Fleiss, J.L. (1979), Intraclass correlation: uses in assessing rater reliability. Psychological Bulletin, 86, 420-428.
</p>


<h3>See Also</h3>

<p><code>finn</code>,
<code>meancor</code>,
<code>robinson</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(anxiety)
icc(anxiety, model="twoway", type="agreement")

r1 &lt;- round(rnorm(20, 10, 4))
r2 &lt;- round(r1 + 10 + rnorm(20, 0, 2))
r3 &lt;- round(r1 + 20 + rnorm(20, 0, 2))
icc(cbind(r1, r2, r3), "twoway")              # High consistency
icc(cbind(r1, r2, r3), "twoway", "agreement") # Low agreement
</code></pre>


</div>