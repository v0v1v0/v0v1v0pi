<div class="container">

<table style="width: 100%;"><tr>
<td>imageseg-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Overview of the imageseg package
</h2>

<h3>Description</h3>

<p>This package provides a streamlined workflow for image segmentation using deep learning models based on the U-Net architecture by Ronneberger (2015) and the U-Net++ architecture by Zhou et al. (2018). Image segmentation is the labelling of each pixel in a images with class labels. Models are convolutional neural networks implemented in <span class="pkg">keras</span> using a TensorFlow backend. The workflow supports grayscale and color images as input, and binary or multi-class output.
</p>
<p>We provide pre-trained models for two forest structural metrics: canopy density and understory vegetation density. These trained models were trained with large and diverse training data sets, allowing for robust inferences. The package workflow is implemented in a few function, allowing for simple predictions on your own images without specialist knowledge of convolutional neural networks.
</p>
<p>If you have training data available, you can also create and train your own models, or continue model training on the pre-trained models.
</p>
<p>The workflow implemented here can also be used for other image segmentation tasks, e.g. in the cell biology or for medical images. We provide two examples in the package vignette (bacteria detection in darkfield microscopy from color images, breast cancer detection in grayscale ultrasound images).
</p>


<h3>Functions for model predictions</h3>

<p>The following functions are used to perform image segmentation on your images. They resize images, load them into R, convert them to model input, load the model and perform predictions. The functions are given in the order they would typically be run. See the vignette for complete examples.
</p>

<table>
<tr>
<td style="text-align: left;">
<code>findValidRegion</code> </td>
<td style="text-align: left;"> Subset image to valid (informative) region (optional) </td>
</tr>
<tr>
<td style="text-align: left;">
<code>resizeImages</code> </td>
<td style="text-align: left;"> Resize and save images </td>
</tr>
<tr>
<td style="text-align: left;">
<code>loadImages</code> </td>
<td style="text-align: left;">  Load image files with magick </td>
</tr>
<tr>
<td style="text-align: left;">

<code>imagesToKerasInput</code> </td>
<td style="text-align: left;"> Convert magick images to array for keras </td>
</tr>
<tr>
<td style="text-align: left;">
<code>loadModel</code> </td>
<td style="text-align: left;"> Load TensorFlow model from hdf5 file </td>
</tr>
<tr>
<td style="text-align: left;">
<code>imageSegmentation</code> </td>
<td style="text-align: left;"> Model predictions from images based on TensorFlow model </td>
</tr>
<tr>
<td style="text-align: left;">

</td>
</tr>
</table>
<h3>Functions for model training</h3>

<p>This function assist in creating models in keras based on the U-Net architecture. See the vignette for complete examples.
</p>

<table>
<tr>
<td style="text-align: left;">
<code>dataAugmentation</code> </td>
<td style="text-align: left;"> Rotating and mirroring images, and modulating colors </td>
</tr>
<tr>
<td style="text-align: left;">
<code>u_net</code>  </td>
<td style="text-align: left;"> Create a U-Net architecture </td>
</tr>
<tr>
<td style="text-align: left;">
<code>u_net_plusplus</code>  </td>
<td style="text-align: left;"> Create a U-Net++ architecture </td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<h3>Download pre-trained models for forest structural metrics</h3>

<p>Links to both pre-trained models (canopy and understory), example classifications and all training data used can be found in the GitHub readme under:
</p>
<p><a href="https://github.com/EcoDynIZW/imageseg">https://github.com/EcoDynIZW/imageseg</a>
</p>


<h3>Vignette</h3>

<p>The package contains a pdf vignette demonstrating the workflow for predictions and model training using various examples. It covers installation and setup, model predictions and training the forest structural models, and two more general applications of image segmentation (multi-class image segmentation of RGB microscopy images, and single-class image segmentation of grayscale ultrasound breast scan images). See <code>browseVignettes(package = "imageseg")</code>.
</p>


<h3>Author(s)</h3>

<p>Juergen Niedballa, Jan Axtner
</p>
<p><b>Maintainer</b>: Juergen Niedballa &lt;niedballa@izw-berlin.de&gt;
</p>


<h3>References</h3>

<p>Ronneberger O., Fischer P., Brox T. (2015) U-Net: Convolutional Networks for Biomedical Image Segmentation. In: Navab N., Hornegger J., Wells W., Frangi A. (eds) Medical Image Computing and Computer-Assisted Intervention â€“ MICCAI 2015. MICCAI 2015. Lecture Notes in Computer Science, vol 9351. Springer, Cham.
doi: <a href="https://doi.org/10.1007/978-3-319-24574-4_28">10.1007/978-3-319-24574-4_28</a>
</p>
<p>Zhou, Z., Rahman Siddiquee, M. M., Tajbakhsh, N., &amp; Liang, J. (2018). Unet++: A nested u-net architecture for medical image segmentation. In Deep learning in medical image analysis and multimodal learning for clinical decision support (pp. 3-11). Springer, Cham.
doi: <a href="https://doi.org/10.48550/arXiv.1807.10165">10.48550/arXiv.1807.10165</a>
</p>


<h3>See Also</h3>

<p><span class="pkg">keras</span>
<span class="pkg">tensorflow</span>
<span class="pkg">magick</span>
</p>


</div>