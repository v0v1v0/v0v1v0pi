<div class="container">

<table style="width: 100%;"><tr>
<td>condinformation</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>conditional mutual information computation</h2>

<h3>Description</h3>

<p><code>condinformation</code> takes three random variables as input and computes the 
conditional mutual information in nats according to the entropy estimator <code>method</code>.
If S is not supplied the function returns the mutual information between X and Y - see <code>mutinformation</code>
</p>


<h3>Usage</h3>

<pre><code class="language-R">condinformation(X, Y, S=NULL, method="emp")</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>vector/factor denoting a random variable or a data.frame denoting a random vector where columns contain variables/features and rows contain outcomes/samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>another random variable or random vector (vector/factor or data.frame).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>S</code></td>
<td>
<p>the conditioning random variable or random vector (vector/factor or data.frame).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The name of the entropy estimator. The package implements four estimators : 
"emp", "mm", "shrink", "sg" (default:"emp") - see details. 
These estimators require discrete data values - see <code>discretize</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>


<ul>
<li>
<p> "emp" : This estimator computes the entropy of the empirical probability distribution.
</p>
</li>
<li>
<p> "mm" : This is the Miller-Madow asymptotic bias corrected empirical estimator.
</p>
</li>
<li>
<p> "shrink" : This is a shrinkage estimate of the entropy of a Dirichlet probability distribution.
</p>
</li>
<li>
<p> "sg" : This is the Schurmann-Grassberger estimate of the entropy of a Dirichlet probability distribution.
</p>
</li>
</ul>
<h3>Value</h3>

 <p><code>condinformation</code> returns the conditional mutual information, I(X;Y|S), in nats.</p>


<h3>Author(s)</h3>

<p>Patrick E. Meyer
</p>


<h3>References</h3>

<p>Meyer,  P. E.  (2008). Information-Theoretic Variable Selection and Network Inference from Microarray Data. PhD thesis of the Universite Libre de Bruxelles.
</p>
<p>Cover, T. M. and Thomas, J. A. (1990). Elements of Information Theory. John Wiley,
New York.
</p>


<h3>See Also</h3>

<p><code>mutinformation</code>, <code>multiinformation</code>, <code>interinformation</code>, <code>natstobits</code></p>


<h3>Examples</h3>

<pre><code class="language-R">  data(USArrests)
  dat&lt;-discretize(USArrests)
  I &lt;- condinformation(dat[,1],dat[,2],dat[,3],method="emp")
</code></pre>


</div>