<div class="container">

<table style="width: 100%;"><tr>
<td>entropy</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Information measures</h2>

<h3>Description</h3>

<p>Compute information-based estimates and distances.
</p>


<h3>Usage</h3>

<pre><code class="language-R">entropy(.data, .base = 2, .norm = FALSE, .do.norm = NA, .laplace = 1e-12)

kl_div(.alpha, .beta, .base = 2, .do.norm = NA, .laplace = 1e-12)

js_div(.alpha, .beta, .base = 2, .do.norm = NA, .laplace = 1e-12, .norm.entropy = FALSE)

cross_entropy(.alpha, .beta, .base = 2, .do.norm = NA,
              .laplace = 1e-12, .norm.entropy = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>.data</code></td>
<td>
<p>Numeric vector. Any distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.base</code></td>
<td>
<p>Numeric. A base of logarithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.norm</code></td>
<td>
<p>Logical. If TRUE then normalises the entropy by the maximal value of the entropy.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.do.norm</code></td>
<td>
<p>If TRUE then normalises the input distributions to make them sum up to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.laplace</code></td>
<td>
<p>Numeric. A value for the laplace correction.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.alpha</code></td>
<td>
<p>Numeric vector. A distribution of some random value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.beta</code></td>
<td>
<p>Numeric vector. A distribution of some random value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>.norm.entropy</code></td>
<td>
<p>Logical. If TRUE then normalises the resulting value by the average entropy of input distributions.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A numeric value.
</p>


<h3>Examples</h3>

<pre><code class="language-R">P &lt;- abs(rnorm(10))
Q &lt;- abs(rnorm(10))
entropy(P)
kl_div(P, Q)
js_div(P, Q)
cross_entropy(P, Q)
</code></pre>


</div>