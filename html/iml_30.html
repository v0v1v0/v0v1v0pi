<div class="container">

<table style="width: 100%;"><tr>
<td>TreeSurrogate</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Decision tree surrogate model</h2>

<h3>Description</h3>

<p><code>TreeSurrogate</code> fits a decision tree on the predictions of a prediction model.
</p>


<h3>Details</h3>

<p>A conditional inference tree is fitted on the predicted <code class="reqn">\hat{y}</code> from
the machine learning model and the data. The <code>partykit</code> package and
function are used to fit the tree. By default a tree of maximum depth of 2 is
fitted to improve interpretability.
</p>
<p>To learn more about global surrogate models, read the Interpretable Machine
Learning book:
<a href="https://christophm.github.io/interpretable-ml-book/global.html">https://christophm.github.io/interpretable-ml-book/global.html</a>
</p>


<h3>Super class</h3>

<p><code>iml::InterpretationMethod</code> -&gt; <code>TreeSurrogate</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>tree</code></dt>
<dd>
<p><code>party</code><br>
The fitted tree. See also partykit::ctree.</p>
</dd>
<dt><code>maxdepth</code></dt>
<dd>
<p><code>numeric(1)</code><br>
The maximum tree depth.</p>
</dd>
<dt><code>r.squared</code></dt>
<dd>
<p><code>numeric(1|n.classes)</code><br>
R squared measures how well the decision tree approximates the
underlying model. It is calculated as 1 - (variance of prediction
differences / variance of black box model predictions). For the
multi-class case, r.squared contains one measure per class.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TreeSurrogate-new"><code>TreeSurrogate$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TreeSurrogate-predict"><code>TreeSurrogate$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-TreeSurrogate-clone"><code>TreeSurrogate$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href="../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot"><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href="../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print"><code>iml::InterpretationMethod$print()</code></a></span></li>
</ul></details><hr>
<a id="method-TreeSurrogate-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Create a TreeSurrogate object
</p>


<h5>Usage</h5>

<div class="r"><pre>TreeSurrogate$new(predictor, maxdepth = 2, tree.args = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt>
<dd>
<p>Predictor<br>
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>maxdepth</code></dt>
<dd>
<p><code>numeric(1)</code><br>
The maximum depth of the tree. Default is 2.</p>
</dd>
<dt><code>tree.args</code></dt>
<dd>
<p>(named list)<br>
Further arguments for <code>party::ctree()</code>.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-TreeSurrogate-predict"></a>



<h4>Method <code>predict()</code>
</h4>

<p>Predict new data with the tree.
See also predict.TreeSurrogate
</p>


<h5>Usage</h5>

<div class="r"><pre>TreeSurrogate$predict(newdata, type = "prob", ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>newdata</code></dt>
<dd>
<p>data.frame<br>
Data to predict on.</p>
</dd>
<dt><code>type</code></dt>
<dd>
<p>Prediction type.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>Further arguments passed to <code>predict()</code>.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-TreeSurrogate-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TreeSurrogate$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>References</h3>

<p>Craven, M., &amp; Shavlik, J. W. (1996). Extracting tree-structured
representations of trained networks. In Advances in neural information
processing systems (pp. 24-30).
</p>


<h3>See Also</h3>

<p>predict.TreeSurrogate plot.TreeSurrogate
</p>
<p>For the tree implementation
<code>partykit::ctree()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("randomForest")
# Fit a Random Forest on the Boston housing data set
data("Boston", package = "MASS")
rf &lt;- randomForest(medv ~ ., data = Boston, ntree = 50)
# Create a model object
mod &lt;- Predictor$new(rf, data = Boston[-which(names(Boston) == "medv")])

# Fit a decision tree as a surrogate for the whole random forest
dt &lt;- TreeSurrogate$new(mod)

# Plot the resulting leaf nodes
plot(dt)

# Use the tree to predict new data
predict(dt, Boston[1:10, ])

# Extract the results
dat &lt;- dt$results
head(dat)

# It also works for classification
rf &lt;- randomForest(Species ~ ., data = iris, ntree = 50)
X &lt;- iris[-which(names(iris) == "Species")]
mod &lt;- Predictor$new(rf, data = X, type = "prob")

# Fit a decision tree as a surrogate for the whole random forest
dt &lt;- TreeSurrogate$new(mod, maxdepth = 2)

# Plot the resulting leaf nodes
plot(dt)

# If you want to visualize the tree directly:
plot(dt$tree)

# Use the tree to predict new data
set.seed(42)
iris.sample &lt;- X[sample(1:nrow(X), 10), ]
predict(dt, iris.sample)
predict(dt, iris.sample, type = "class")

# Extract the dataset
dat &lt;- dt$results
head(dat)
</code></pre>


</div>