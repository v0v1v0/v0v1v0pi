<div class="container">

<table style="width: 100%;"><tr>
<td>leverages</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Leverages</h2>

<h3>Description</h3>

<p>Computes leverage measures from a fitted model object.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  leverages(model, ...)
  ## S3 method for class 'lm'
leverages(model, infl = lm.influence(model, do.coef = FALSE), ...)
  ## S3 method for class 'ols'
leverages(model, ...)
  ## S3 method for class 'ridge'
leverages(model, ...)

  ## S3 method for class 'ols'
hatvalues(model, ...)
  ## S3 method for class 'ridge'
hatvalues(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p> an <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> object, returned by <code>lm</code>, <code>ols</code> or <code>ridge</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>infl</code></td>
<td>
<p> influence structure as returned by <code>lm.influence</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p> further arguments passed to or from other methods.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A vector containing the diagonal of the prediction (or ‘hat’) matrix. 
</p>
<p>For linear regression (i.e., for <code>"lm"</code> or <code>"ols"</code> objects) the prediction matrix assumes 
the form 
</p>
<p style="text-align: center;"><code class="reqn">\bold{H} = \bold{X}(\bold{X}^T\bold{X})^{-1}\bold{X}^T,</code>
</p>

<p>in which case, <code class="reqn">h_{ii} = \bold{x}_i^T(\bold{X}^T\bold{X})^{-1}\bold{x}_i</code> for <code class="reqn">i=1,\dots,n</code>. Whereas
for ridge regression, the prediction matrix is given by 
</p>
<p style="text-align: center;"><code class="reqn">\bold{H}(\lambda) = \bold{X}(\bold{X}^T\bold{X} + \lambda\bold{I})^{-1}\bold{X}^T,</code>
</p>

<p>where <code class="reqn">\lambda</code> represents the ridge parameter. Thus, the diagonal elements of <code class="reqn">\bold{H}(\lambda)</code>,
are <code class="reqn">h_{ii}(\lambda) = \bold{x}_i^T(\bold{X}^T\bold{X} + \lambda\bm{I})^{-1}\bold{x}_i</code>, <code class="reqn">i=1,\dots,n</code>.
</p>


<h3>Note</h3>

<p>This function never creates the prediction matrix and only obtains its diagonal elements from 
the singular value decomposition of <code class="reqn">\bold{X}</code>.
</p>
<p>Function <code>hatvalues</code> only is a wrapper for function <code>leverages</code>.
</p>


<h3>References</h3>

<p>Chatterjee, S., Hadi, A.S. (1988).
<em>Sensivity Analysis in Linear Regression</em>.
Wiley, New York.
</p>
<p>Cook, R.D., Weisberg, S. (1982).
<em>Residuals and Influence in Regression</em>.
Chapman and Hall, London.
</p>
<p>Walker, E., Birch, J.B. (1988).
Influence measures in ridge regression.
<em>Technometrics</em> <b>30</b>, 221-227.
<a href="https://doi.org/10.1080/00401706.1988.10488370">doi:10.1080/00401706.1988.10488370</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Leverages for linear regression
fm &lt;- ols(stack.loss ~ ., data = stackloss)
lev &lt;- leverages(fm)
cutoff &lt;- 2 * mean(lev)
plot(lev, ylab = "Leverages", ylim = c(0,0.45))
abline(h = cutoff, lty = 2, lwd = 2, col = "red")
text(17, lev[17], label = as.character(17), pos = 3)

# Leverages for ridge regression
data(portland)
fm &lt;- ridge(y ~ ., data = portland)
lev &lt;- leverages(fm)
cutoff &lt;- 2 * mean(lev)
plot(lev, ylab = "Leverages", ylim = c(0,0.7))
abline(h = cutoff, lty = 2, lwd = 2, col = "red")
text(10, lev[10], label = as.character(10), pos = 3)
</code></pre>


</div>