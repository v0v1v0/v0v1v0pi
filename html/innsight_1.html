<div class="container">

<table style="width: 100%;"><tr>
<td>innsight-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Get the insight of your neural network</h2>

<h3>Description</h3>

<p><code>innsight</code> is an R package that interprets the behavior and explains
individual predictions of modern neural networks. Many methods for
explaining individual predictions already exist, but hardly any of them
are implemented or available in R. Most of these so-called
<em>feature attribution</em> methods are only implemented in Python and,
thus, difficult to access or use for the R community. In this sense,
the package <code>innsight</code> provides a common interface for various methods
for the interpretability of neural networks and can therefore be considered
as an R analogue to 'iNNvestigate' or 'Captum' for Python.
</p>


<h3>Details</h3>

<p>This package implements several model-specific interpretability
(feature attribution) methods based on neural networks in R, e.g.,
</p>

<ul>
<li> <p><em>Layer-wise relevance propagation (LRP)</em>
</p>

<ul><li>
<p> Including propagation rules: <code class="reqn">\epsilon</code>-rule and
<code class="reqn">\alpha</code>-<code class="reqn">\beta</code>-rule
</p>
</li></ul>
</li>
<li> <p><em>Deep learning important features (DeepLift)</em>
</p>

<ul><li>
<p> Including propagation rules for non-linearities: <em>Rescale</em> rule and
<em>RevealCancel</em> rule
</p>
</li></ul>
</li>
<li> <p>DeepSHAP
</p>
</li>
<li>
<p> Gradient-based methods:
</p>

<ul>
<li> <p><em>Vanilla Gradient</em>, including <em>Gradient<code class="reqn">\times</code>Input</em>
</p>
</li>
<li>
<p> Smoothed gradients <em>(SmoothGrad)</em>, including <em>SmoothGrad<code class="reqn">\times</code>Input</em>
</p>
</li>
<li> <p><em>Integrated gradients</em> (IntegratedGradient)
</p>
</li>
<li> <p><em>Expected gradients</em> (ExpectedGradient)
</p>
</li>
</ul>
</li>
<li> <p><em>ConnectionWeights</em>
</p>
</li>
<li>
<p> Model-agnostic methods:
</p>

<ul>
<li> <p><em>Local interpretable model-agnostic explanation (LIME)</em>
</p>
</li>
<li> <p><em>Shapley values</em> (SHAP)
</p>
</li>
</ul>
</li>
</ul>
<p>The package <code>innsight</code> aims to be as flexible as possible and independent
of a specific deep learning package in which the passed network has been
learned. Basically, a neural network of the libraries
<code>torch::nn_sequential</code>, <code>keras::keras_model_sequential</code>,
<code>keras::keras_model</code> and <code>neuralnet::neuralnet</code> can be passed to the
main building block <code>Converter</code>,
which converts and stores the passed model as a torch model
(<code>ConvertedModel</code>) with special insights needed for interpretation.
It is also possible to pass an arbitrary net in form of a named list
(see details in <code>Converter</code>).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Niklas Koenen <a href="mailto:niklas.koenen@gmail.com">niklas.koenen@gmail.com</a> (<a href="https://orcid.org/0000-0002-4623-8271">ORCID</a>)
</p>
<p>Other contributors:
</p>

<ul><li>
<p> Raphael Baudeu <a href="mailto:raphael.baudeu@gmail.com">raphael.baudeu@gmail.com</a> [contributor]
</p>
</li></ul>
<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://bips-hb.github.io/innsight/">https://bips-hb.github.io/innsight/</a>
</p>
</li>
<li> <p><a href="https://github.com/bips-hb/innsight/">https://github.com/bips-hb/innsight/</a>
</p>
</li>
<li>
<p> Report bugs at <a href="https://github.com/bips-hb/innsight/issues/">https://github.com/bips-hb/innsight/issues/</a>
</p>
</li>
</ul>
</div>