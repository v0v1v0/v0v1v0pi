<div class="container">

<table style="width: 100%;"><tr>
<td>plot.FeatureImp</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plot Feature Importance</h2>

<h3>Description</h3>

<p><code>plot.FeatureImp()</code> plots the feature importance results of a FeatureImp
object.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'FeatureImp'
plot(x, sort = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A FeatureImp object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sort</code></td>
<td>
<p>logical. Should the features be sorted in descending order?
Defaults to TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments for the objects plot function</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The plot shows the importance per feature.
</p>
<p>When <code>n.repetitions</code> in <code>FeatureImp$new</code> was larger than 1, then we get
multiple importance estimates per feature. The importance are aggregated and
the plot shows the median importance per feature (as dots) and also the
90%-quantile, which helps to understand how much variance the computation has
per feature.
</p>


<h3>Value</h3>

<p>ggplot2 plot object
</p>


<h3>See Also</h3>

<p>FeatureImp
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("rpart")
# We train a tree on the Boston dataset:
data("Boston", package = "MASS")
tree &lt;- rpart(medv ~ ., data = Boston)
y &lt;- Boston$medv
X &lt;- Boston[-which(names(Boston) == "medv")]
mod &lt;- Predictor$new(tree, data = X, y = y)

# Compute feature importances as the performance drop in mean absolute error
imp &lt;- FeatureImp$new(mod, loss = "mae")

# Plot the results directly
plot(imp)
</code></pre>


</div>