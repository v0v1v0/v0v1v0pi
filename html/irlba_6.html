<div class="container">

<table style="width: 100%;"><tr>
<td>svdr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Find a few approximate largest singular values and corresponding
singular vectors of a matrix.</h2>

<h3>Description</h3>

<p>The randomized method for truncated SVD by P. G. Martinsson and colleagues
finds a few approximate largest singular values and corresponding
singular vectors of a sparse or dense matrix. It is a fast and
memory-efficient way to compute a partial SVD, similar in performance
for many problems to <code>irlba</code>. The <code>svdr</code> method
is a block method and may produce more accurate estimations with
less work for problems with clustered large singular values (see
the examples). In other problems, <code>irlba</code> may exhibit faster
convergence.
</p>


<h3>Usage</h3>

<pre><code class="language-R">svdr(x, k, tol = 1e-05, it = 100L, extra = min(10L, dim(x) - k),
  center = NULL, Q = NULL, return.Q = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>numeric real- or complex-valued matrix or real-valued sparse matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>dimension of subspace to estimate (number of approximate singular values to compute).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>stop iteration when the largest absolute relative change in estimated singular
values from one iteration to the next falls below this value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>it</code></td>
<td>
<p>maximum number of algorithm iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extra</code></td>
<td>
<p>number of extra vectors of dimension <code>ncol(x)</code>, larger values generally improve accuracy (with increased
computational cost).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>optional column centering vector whose values are implicitly subtracted from each
column of <code>A</code> without explicitly forming the centered matrix (preserving sparsity).
Optionally specify <code>center=TRUE</code> as shorthand for <code>center=colMeans(x)</code>.
Use for efficient principal components computation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Q</code></td>
<td>
<p>optional initial random matrix, defaults to a matrix of size <code>ncol(x)</code> by <code>k + extra</code> with
entries sampled from a normal random distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.Q</code></td>
<td>
<p>if <code>TRUE</code> return the <code>Q</code> matrix for restarting (see examples).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Also see an alternate implementation (<code>rsvd</code>) of this method by N. Benjamin Erichson
in the https://cran.r-project.org/package=rsvd package.
</p>


<h3>Value</h3>

<p>Returns a list with entries:
</p>

<dl>
<dt>d:</dt>
<dd>
<p> k approximate singular values</p>
</dd>
<dt>u:</dt>
<dd>
<p> k approximate left singular vectors</p>
</dd>
<dt>v:</dt>
<dd>
<p> k approximate right singular vectors</p>
</dd>
<dt>mprod:</dt>
<dd>
<p> total number of matrix products carried out</p>
</dd>
<dt>Q:</dt>
<dd>
<p> optional subspace matrix (when <code>return.Q=TRUE</code>)</p>
</dd>
</dl>
<h3>References</h3>

<p>Finding structure with randomness: Stochastic algorithms for constructing
approximate matrix decompositions N. Halko, P. G. Martinsson, J. Tropp. Sep. 2009.
</p>


<h3>See Also</h3>

<p><code>irlba</code>, <code>svd</code>, <code>rsvd</code> in the rsvd package
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(1)

A &lt;- matrix(runif(400), nrow=20)
svdr(A, 3)$d

# Compare with svd
svd(A)$d[1:3]

# Compare with irlba
irlba(A, 3)$d

## Not run: 
# A problem with clustered large singular values where svdr out-performs irlba.
tprolate &lt;- function(n, w=0.25)
{
  a &lt;- rep(0, n)
  a[1] &lt;- 2 * w
  a[2:n] &lt;- sin( 2 * pi * w * (1:(n-1)) ) / ( pi * (1:(n-1)) )
  toeplitz(a)
}

x &lt;- tprolate(512)
set.seed(1)
tL &lt;- system.time(L &lt;- irlba(x, 20))
tR &lt;- system.time(R &lt;- svdr(x, 20))
S &lt;- svd(x)
plot(S$d)
data.frame(time=c(tL[3], tR[3]),
           error=sqrt(c(crossprod(L$d - S$d[1:20]), crossprod(R$d - S$d[1:20]))),
           row.names=c("IRLBA", "Randomized SVD"))

# But, here is a similar problem with clustered singular values where svdr
# doesn't out-perform irlba as easily...clusters of singular values are,
# in general, very hard to deal with!
# (This example based on https://github.com/bwlewis/irlba/issues/16.)
set.seed(1)
s &lt;- svd(matrix(rnorm(200 * 200), 200))
x &lt;- s$u %*% (c(exp(-(1:100)^0.3) * 1e-12 + 1, rep(0.5, 100)) * t(s$v))
tL &lt;- system.time(L &lt;- irlba(x, 5))
tR &lt;- system.time(R &lt;- svdr(x, 5))
S &lt;- svd(x)
plot(S$d)
data.frame(time=c(tL[3], tR[3]),
           error=sqrt(c(crossprod(L$d - S$d[1:5]), crossprod(R$d - S$d[1:5]))),
           row.names=c("IRLBA", "Randomized SVD"))

## End(Not run)
</code></pre>


</div>